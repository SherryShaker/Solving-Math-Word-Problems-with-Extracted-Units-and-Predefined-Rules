{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (2.8.1)\n",
      "Collecting gdown==4.4.0\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: more-itertools in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (8.4.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (3.2.2)\n",
      "Requirement already satisfied: torch!=1.8,>=1.5.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (1.10.2)\n",
      "Requirement already satisfied: tabulate in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (0.8.7)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Collecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "Collecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (4.48.2)\n",
      "Requirement already satisfied: transformers>=4.0.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (4.12.5)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (0.1.95)\n",
      "Note: you may need to restart the kernel to use updated packages.Collecting segtok>=1.5.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda 4.11.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: huggingface-hub in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (0.8.1)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "Collecting hyperopt>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting pptree\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: regex in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (2020.7.14)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (0.23.1)\n",
      "Requirement already satisfied: lxml in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (4.5.2)\n",
      "Requirement already satisfied: gensim>=3.4.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from flair) (4.1.2)\n",
      "Requirement already satisfied: requests[socks] in j:\\anaconda\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair) (2.24.0)\n",
      "Requirement already satisfied: filelock in j:\\anaconda\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair) (3.0.12)\n",
      "Requirement already satisfied: beautifulsoup4 in j:\\anaconda\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair) (4.9.1)\n",
      "Requirement already satisfied: six in j:\\anaconda\\anaconda3\\lib\\site-packages (from gdown==4.4.0->flair) (1.15.0)\n",
      "Requirement already satisfied: numpy in j:\\anaconda\\anaconda3\\lib\\site-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in j:\\anaconda\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (1.5.0)\n",
      "Requirement already satisfied: Cython==0.29.23 in j:\\anaconda\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Requirement already satisfied: future in j:\\anaconda\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair) (0.18.2)\n",
      "Requirement already satisfied: cloudpickle in j:\\anaconda\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair) (1.5.0)\n",
      "Requirement already satisfied: py4j in j:\\anaconda\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair) (0.10.9)\n",
      "Requirement already satisfied: networkx>=2.2 in j:\\anaconda\\anaconda3\\lib\\site-packages (from hyperopt>=0.2.7->flair) (2.4)\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in j:\\anaconda\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in j:\\anaconda\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in j:\\anaconda\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from networkx>=2.2->hyperopt>=0.2.7->flair) (4.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in j:\\anaconda\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in j:\\anaconda\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (2021.10.8)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in j:\\anaconda\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->flair) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in j:\\anaconda\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (21.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in j:\\anaconda\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (5.3.1)\n",
      "Requirement already satisfied: sacremoses in j:\\anaconda\\anaconda3\\lib\\site-packages (from transformers>=4.0.0->flair) (0.0.46)\n",
      "Requirement already satisfied: soupsieve>1.2 in j:\\anaconda\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.0.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in j:\\anaconda\\anaconda3\\lib\\site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in j:\\anaconda\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
      "Requirement already satisfied: click in j:\\anaconda\\anaconda3\\lib\\site-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
      "Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=1bd0b6ddc4cf322dc8717efaca17ef9e7005d976cae04121b3f9bd7e845b6408\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\fb\\c3\\0e\\c4d8ff8bfcb0461afff199471449f642179b74968c15b7a69c\n",
      "  Building wheel for mpld3 (setup.py): started\n",
      "  Building wheel for mpld3 (setup.py): finished with status 'done'\n",
      "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=e244ec82d5ec78eaa9807edead7fc456403c3c2570434f4ce499b3f369088eb9\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\26\\70\\6a\\1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10175 sha256=e10a8b7db41649bfa146ccf14d8a1f8d254bc74d5ed7105b051c29ebf3fb1f48\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\3a\\0d\\38\\01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
      "  Building wheel for sqlitedict (setup.py): started\n",
      "  Building wheel for sqlitedict (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15718 sha256=11ddbe8fb3a6d8309dd553ac2b903ffb830f2987ba251e0946b9bc90a3d404d7\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\96\\dd\\2e\\0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=d3907cd33f42e18c6c1a31e04ce796242b80a3eeb44655183312a83782c93eea\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\c5\\96\\8a\\f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "  Building wheel for pptree (setup.py): started\n",
      "  Building wheel for pptree (setup.py): finished with status 'done'\n",
      "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=a801b67c3457ad40533d75decd473e8b53981b33fe19c9a149d4af8180f63322\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\9e\\e8\\7d\\a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
      "  Building wheel for wikipedia-api (setup.py): started\n",
      "  Building wheel for wikipedia-api (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13462 sha256=1f3c71a8dcc599d2cafc8fe824f911f49be7fedef649686f65c14651c5826b66\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\d3\\24\\56\\58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
      "Successfully built gdown mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
      "Installing collected packages: charset-normalizer, requests, importlib-metadata, overrides, wikipedia-api, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.24.0\n",
      "    Uninstalling requests-2.24.0:\n",
      "      Successfully uninstalled requests-2.24.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.7.0\n",
      "    Uninstalling importlib-metadata-1.7.0:\n",
      "      Successfully uninstalled importlib-metadata-1.7.0\n",
      "Successfully installed bpemb-0.3.3 charset-normalizer-2.1.0 conllu-4.5.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 gdown-4.4.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 requests-2.28.1 segtok-1.5.11 sqlitedict-2.0.0 wikipedia-api-0.5.4\n"
     ]
    }
   ],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q, ME, MP, Qlr Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 14:30:18,110 Reading data from C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\n",
      "2022-08-11 14:30:18,112 Train: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\train.txt\n",
      "2022-08-11 14:30:18,114 Dev: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\dev.txt\n",
      "2022-08-11 14:30:18,116 Test: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train and test files reside\n",
    "data_folder = 'C:/Users/DELL/Desktop/MeasEval/NER_sent'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              dev_file='dev.txt',\n",
    "                              test_file='test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: \"Data were drawn from the Whitehall II study with baseline examination in 1991 ; follow - up screenings in 1997 , 2003 , and 2008 ; and additional disease ascertainment from hospital data and registry linkage on 5318 participants ( mean age 54 . 8 years , 31 % women ) without depressive symptoms at baseline .\" → [\"Whitehall II study\"/MeasuredEntity, \"baseline examination\"/MeasuredEntity, \"1991\"/Quantity, \"follow - up screenings\"/MeasuredEntity, \"1997 , 2003 , and 2008\"/Quantity, \"5318 participants\"/MeasuredEntity, \"mean age\"/MeasuredProperty, \"54 . 8 years\"/Quantity, \"31 %\"/Quantity, \"women\"/MeasuredProperty]\n"
     ]
    }
   ],
   "source": [
    "print(corpus.train[0].to_tagged_string('ner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 14:30:30,664 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1943it [00:00, 14931.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 14:30:30,807 Dictionary created for label 'ner' with 5 values: Quantity (seen 1124 times), MeasuredEntity (seen 907 times), MeasuredProperty (seen 644 times), Qualifier (seen 90 times)\n",
      "Dictionary with 5 tags: <unk>, Quantity, MeasuredEntity, MeasuredProperty, Qualifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. what label do we want to predict?\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(label_dict)\n",
    "\n",
    "# # 4. initialize fine-tuneable transformer embeddings WITH document context\n",
    "# embeddings = TransformerWordEmbeddings(model='xlm-roberta-large',\n",
    "#                                        layers=\"-1\",\n",
    "#                                        subtoken_pooling=\"first\",\n",
    "#                                        fine_tune=True,\n",
    "#                                        use_context=True,\n",
    "#                                        )\n",
    "\n",
    "# # 5. initialize bare-bones sequence tagger (no CRF, no RNN, no reprojection)\n",
    "# tagger = SequenceTagger(hidden_size=256,\n",
    "#                         embeddings=embeddings,\n",
    "#                         tag_dictionary=label_dict,\n",
    "#                         tag_type='ner',\n",
    "#                         use_crf=False,\n",
    "#                         use_rnn=False,\n",
    "#                         reproject_embeddings=False,\n",
    "#                         )\n",
    "\n",
    "# # 6. initialize trainer\n",
    "# trainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# # 7. run fine-tuning\n",
    "# trainer.fine_tune('resources/taggers/sota-ner-flert',\n",
    "#                   learning_rate=5.0e-6,\n",
    "#                   mini_batch_size=4,\n",
    "#                   mini_batch_chunk_size=1,  # remove this parameter to speed up computation if you have a big GPU\n",
    "#                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61f94922e214bf2a76850f96ed308e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3861fd470384463b1f18a242664abb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=829.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a672e1d4dea74754953edcdd6bf7fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ff5385b4b49e4971e9a43ab6cac89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c80e4aeeb548a3bde00429a7e0a10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a20ff5e68a49a581bcee338501fd44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433316646.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. initialize fine-tuneable transformer embeddings WITH document context\n",
    "embeddings = TransformerWordEmbeddings(model='dslim/bert-base-NER',\n",
    "                                       layers=\"-1\",\n",
    "                                       subtoken_pooling=\"first\",\n",
    "                                       fine_tune=True,\n",
    "                                       allow_long_sentences=True,\n",
    "                                       use_context=True,\n",
    "                                       layer_mean=False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 16:51:23,152 SequenceTagger predicts: Dictionary with 17 tags: O, S-Quantity, B-Quantity, E-Quantity, I-Quantity, S-MeasuredEntity, B-MeasuredEntity, E-MeasuredEntity, I-MeasuredEntity, S-MeasuredProperty, B-MeasuredProperty, E-MeasuredProperty, I-MeasuredProperty, S-Qualifier, B-Qualifier, E-Qualifier, I-Qualifier\n"
     ]
    }
   ],
   "source": [
    "# 5. initialize bare-bones sequence tagger (no CRF, no RNN, no reprojection)\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type='ner',\n",
    "                        use_crf=True,\n",
    "                        use_rnn=False,\n",
    "                        reproject_embeddings=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 17:47:59,372 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,415 Model: \"SequenceTagger(\n",
      "  (embeddings): TransformerWordEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (linear): Linear(in_features=768, out_features=19, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-11 17:47:59,426 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,438 Corpus: \"Corpus: 1943 train + 281 dev + 561 test sentences\"\n",
      "2022-08-11 17:47:59,441 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,444 Parameters:\n",
      "2022-08-11 17:47:59,446  - learning_rate: \"0.000005\"\n",
      "2022-08-11 17:47:59,449  - mini_batch_size: \"4\"\n",
      "2022-08-11 17:47:59,452  - patience: \"3\"\n",
      "2022-08-11 17:47:59,455  - anneal_factor: \"0.5\"\n",
      "2022-08-11 17:47:59,458  - max_epochs: \"10\"\n",
      "2022-08-11 17:47:59,461  - shuffle: \"True\"\n",
      "2022-08-11 17:47:59,464  - train_with_dev: \"False\"\n",
      "2022-08-11 17:47:59,467  - batch_growth_annealing: \"False\"\n",
      "2022-08-11 17:47:59,470 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,473 Model training base path: \"resources\\taggers\\ner-flert\"\n",
      "2022-08-11 17:47:59,477 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,486 Device: cpu\n",
      "2022-08-11 17:47:59,491 ----------------------------------------------------------------------------------------------------\n",
      "2022-08-11 17:47:59,494 Embeddings storage mode: none\n",
      "2022-08-11 17:47:59,497 ----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 7. run fine-tuning\n",
    "trainer.fine_tune('resources/taggers/ner-flert',\n",
    "                  learning_rate=5.0e-6,\n",
    "                  mini_batch_size=4\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:45:50,284 Reading data from C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\data_unit\n",
      "2022-08-14 20:45:50,289 Train: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\data_unit\\train.txt\n",
      "2022-08-14 20:45:50,291 Dev: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\data_unit\\dev.txt\n",
      "2022-08-14 20:45:50,293 Test: C:\\Users\\DELL\\Desktop\\MeasEval\\NER_sent\\data_unit\\test.txt\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'ner'}\n",
    "\n",
    "# this is the folder in which train and test files reside\n",
    "data_folder = 'C:/Users/DELL/Desktop/MeasEval/NER_sent/data_unit'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              dev_file='dev.txt',\n",
    "                              test_file='test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:45:57,972 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1943it [00:00, 11920.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:45:58,201 Dictionary created for label 'ner' with 2 values: unit (seen 1051 times)\n",
      "Dictionary with 2 tags: <unk>, unit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. what label do we want to predict?\n",
    "label_type = 'ner'\n",
    "\n",
    "# 3. make the label dictionary from the corpus\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize fine-tuneable transformer embeddings WITH document context\n",
    "embeddings = TransformerWordEmbeddings(model='dslim/bert-base-NER',\n",
    "                                       layers=\"-1\",\n",
    "                                       subtoken_pooling=\"first\",\n",
    "                                       fine_tune=True,\n",
    "                                       allow_long_sentences=True,\n",
    "                                       use_context=True,\n",
    "                                       layer_mean=False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-14 20:48:41,277 SequenceTagger predicts: Dictionary with 2 tags: <unk>, unit\n"
     ]
    }
   ],
   "source": [
    "# 5. initialize bare-bones sequence tagger (no CRF, no RNN, no reprojection)\n",
    "tagger = SequenceTagger(hidden_size=256,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type='ner',\n",
    "                        use_crf=True,\n",
    "                        use_rnn=False,\n",
    "                        reproject_embeddings=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. run fine-tuning\n",
    "trainer.fine_tune('resources/taggers/ner-unit-flert',\n",
    "                  learning_rate=5.0e-6,\n",
    "                  mini_batch_size=4\n",
    "                  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
